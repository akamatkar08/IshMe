{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "61ad3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import h5py\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "7a3ec132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading finalized datasets\n",
    "US_data = pd.read_csv(r\"C:\\Users\\akama\\OneDrive\\Desktop\\Data Science Bootcamp\\IshMe\\Capstone 3 - Time Series Analysis\\raw_data\\US_data.csv\")\n",
    "CO_emissions = pd.read_csv(r\"C:\\Users\\akama\\OneDrive\\Desktop\\Data Science Bootcamp\\IshMe\\Capstone 3 - Time Series Analysis\\raw_data\\CO_emissions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf337fe",
   "metadata": {},
   "source": [
    "## Dataset 2 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "88b9e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = CO_emissions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "4f37070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['year'] = pd.to_datetime(df2['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "544fdca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.set_index(df2['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ab45e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "58d0f37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 19)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "dc447bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for lstm\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "41aae1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "bbda0bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1     0.000000   0.529909   0.474903   0.000000   0.000000   0.000000   \n",
      "2     0.010801   0.552596   0.519737   0.034651   0.005939   0.000778   \n",
      "3     0.018749   0.535302   0.549220   0.056319   0.016694   0.001268   \n",
      "4     0.042579   0.631557   0.614279   0.134516   0.025228   0.001759   \n",
      "5     0.040022   0.471637   0.589181   0.120799   0.029605   0.002135   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "115   0.895721   0.539995   0.031189   0.696636   0.836973   0.851670   \n",
      "116   0.868418   0.321670   0.021199   0.552378   0.847267   0.876756   \n",
      "117   0.846441   0.353948   0.012914   0.473562   0.836973   0.883301   \n",
      "118   0.839370   0.444286   0.005361   0.447967   0.856439   0.873133   \n",
      "119   0.870695   0.676974   0.009747   0.413009   0.856439   0.968245   \n",
      "\n",
      "     var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  var11(t-1)  var12(t-1)  \\\n",
      "1     0.000000   0.000000   0.420078    0.000000    0.000000    0.000000   \n",
      "2     0.000958   0.041606   0.468095    0.019608    0.002753    0.002307   \n",
      "3     0.003957   0.067372   0.490968    0.052288    0.004130    0.010426   \n",
      "4     0.005881   0.167591   0.610057    0.078431    0.005506    0.015040   \n",
      "5     0.008572   0.140146   0.568757    0.091503    0.006293    0.021683   \n",
      "..         ...        ...        ...         ...         ...         ...   \n",
      "115   0.858763   0.658467   0.191431    0.692810    0.869420    0.620410   \n",
      "116   0.872859   0.615766   0.123264    0.692810    0.889282    0.626407   \n",
      "117   0.875390   0.580438   0.085232    0.679739    0.890069    0.623916   \n",
      "118   0.881832   0.564161   0.071435    0.692810    0.873746    0.624469   \n",
      "119   0.900465   0.595109   0.053826    0.686275    0.965192    0.634065   \n",
      "\n",
      "     var13(t-1)  var14(t-1)  var15(t-1)  var16(t-1)  var17(t-1)  var18(t-1)  \\\n",
      "1      0.416988    0.631232    1.000000    1.000000    0.319760    0.000000   \n",
      "2      0.416988    0.677175    1.000000    1.000000    0.313761    0.006282   \n",
      "3      0.424710    0.700635    1.000000    0.999621    0.438466    0.012730   \n",
      "4      0.463320    0.766129    1.000000    0.999621    0.500454    0.019347   \n",
      "5      0.467182    0.735826    1.000000    0.999748    0.539356    0.026098   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "115    0.648649    0.097019    0.002562    0.015789    0.003272    0.958484   \n",
      "116    0.664093    0.065005    0.003894    0.016673    0.003999    0.967293   \n",
      "117    0.552124    0.048143    0.002869    0.011494    0.003272    0.975833   \n",
      "118    0.571429    0.040567    0.003279    0.001768    0.000000    0.984099   \n",
      "119    0.768340    0.028104    0.002562    0.015663    0.004908    0.992135   \n",
      "\n",
      "     var19(t-1)   var1(t)  \n",
      "1      0.000000  0.010801  \n",
      "2      0.003943  0.018749  \n",
      "3      0.004344  0.042579  \n",
      "4      0.006263  0.040022  \n",
      "5      0.005741  0.059232  \n",
      "..          ...       ...  \n",
      "115    0.905402  0.868418  \n",
      "116    0.929361  0.846441  \n",
      "117    0.944194  0.839370  \n",
      "118    0.968941  0.870695  \n",
      "119    1.000000  0.845056  \n",
      "\n",
      "[119 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = df2\n",
    "values = df2.values\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "reframed.drop(reframed.columns[[20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37]], axis=1, inplace=True)\n",
    "print(reframed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "91084f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 1, 19) (35,) (84, 1, 19) (84,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 35\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "ce122658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 0s - loss: 0.2089 - val_loss: 0.7762\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 0.2030 - val_loss: 0.7696\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 0.1971 - val_loss: 0.7630\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 0.1912 - val_loss: 0.7563\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 0.1852 - val_loss: 0.7497\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 0.1793 - val_loss: 0.7430\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 0.1733 - val_loss: 0.7362\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 0.1674 - val_loss: 0.7295\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 0.1616 - val_loss: 0.7227\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 0.1558 - val_loss: 0.7159\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 0.1501 - val_loss: 0.7091\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 0.1445 - val_loss: 0.7023\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 0.1390 - val_loss: 0.6954\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 0.1334 - val_loss: 0.6886\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 0.1279 - val_loss: 0.6817\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 0.1223 - val_loss: 0.6748\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 0.1168 - val_loss: 0.6679\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 0.1115 - val_loss: 0.6609\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 0.1062 - val_loss: 0.6540\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 0.1012 - val_loss: 0.6470\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 0.0964 - val_loss: 0.6401\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 0.0917 - val_loss: 0.6332\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 0.0869 - val_loss: 0.6262\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 0.0823 - val_loss: 0.6193\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 0.0778 - val_loss: 0.6124\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 0.0734 - val_loss: 0.6054\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 0.0692 - val_loss: 0.5986\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 0.0656 - val_loss: 0.5918\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 0.0619 - val_loss: 0.5850\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 0.0584 - val_loss: 0.5783\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 0.0551 - val_loss: 0.5717\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 0.0524 - val_loss: 0.5652\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 0.0505 - val_loss: 0.5589\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 0.0491 - val_loss: 0.5529\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 0.0480 - val_loss: 0.5471\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 0.0472 - val_loss: 0.5416\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 0.0469 - val_loss: 0.5366\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 0.0469 - val_loss: 0.5320\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 0.0471 - val_loss: 0.5278\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 0.0472 - val_loss: 0.5239\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 0.0473 - val_loss: 0.5203\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 0.0473 - val_loss: 0.5171\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 0.0473 - val_loss: 0.5141\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 0.0472 - val_loss: 0.5113\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 0.0471 - val_loss: 0.5088\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 0.0470 - val_loss: 0.5065\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 0.0469 - val_loss: 0.5044\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 0.0467 - val_loss: 0.5024\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 0.0465 - val_loss: 0.5006\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 0.0463 - val_loss: 0.4989\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 0.0461 - val_loss: 0.4974\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 0.0458 - val_loss: 0.4960\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 0.0456 - val_loss: 0.4947\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 0.0453 - val_loss: 0.4935\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 0.0450 - val_loss: 0.4924\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 0.0447 - val_loss: 0.4915\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 0.0443 - val_loss: 0.4906\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 0.0440 - val_loss: 0.4899\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 0.0437 - val_loss: 0.4891\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 0.0433 - val_loss: 0.4884\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 0.0430 - val_loss: 0.4877\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 0.0426 - val_loss: 0.4871\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 0.0422 - val_loss: 0.4865\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 0.0419 - val_loss: 0.4859\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 0.0415 - val_loss: 0.4853\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 0.0411 - val_loss: 0.4848\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 0.0407 - val_loss: 0.4843\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 0.0403 - val_loss: 0.4838\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 0.0399 - val_loss: 0.4833\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 0.0395 - val_loss: 0.4828\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 0.0391 - val_loss: 0.4824\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 0.0387 - val_loss: 0.4819\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 0.0383 - val_loss: 0.4815\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 0.0379 - val_loss: 0.4811\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 0.0375 - val_loss: 0.4806\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 0.0370 - val_loss: 0.4802\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 0.0366 - val_loss: 0.4798\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 0.0362 - val_loss: 0.4794\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 0.0358 - val_loss: 0.4789\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 0.0354 - val_loss: 0.4785\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.0351 - val_loss: 0.4778\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.0348 - val_loss: 0.4771\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.0345 - val_loss: 0.4762\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.0342 - val_loss: 0.4752\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.0340 - val_loss: 0.4740\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.0338 - val_loss: 0.4727\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.0335 - val_loss: 0.4712\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.0333 - val_loss: 0.4696\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.0330 - val_loss: 0.4679\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.0327 - val_loss: 0.4660\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.0325 - val_loss: 0.4640\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.0322 - val_loss: 0.4619\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.0319 - val_loss: 0.4597\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.0316 - val_loss: 0.4575\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.0313 - val_loss: 0.4551\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.0309 - val_loss: 0.4527\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.0306 - val_loss: 0.4502\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.0303 - val_loss: 0.4477\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.0300 - val_loss: 0.4452\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.0297 - val_loss: 0.4427\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.0294 - val_loss: 0.4403\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.0291 - val_loss: 0.4378\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.0289 - val_loss: 0.4354\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.0286 - val_loss: 0.4330\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.0283 - val_loss: 0.4308\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.0281 - val_loss: 0.4287\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.0279 - val_loss: 0.4265\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.0277 - val_loss: 0.4244\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.0275 - val_loss: 0.4224\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.0273 - val_loss: 0.4205\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.0271 - val_loss: 0.4189\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.0270 - val_loss: 0.4175\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.0268 - val_loss: 0.4163\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.0266 - val_loss: 0.4152\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.0264 - val_loss: 0.4144\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.0262 - val_loss: 0.4136\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.0260 - val_loss: 0.4128\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.0258 - val_loss: 0.4120\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.0256 - val_loss: 0.4110\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.0255 - val_loss: 0.4100\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.0253 - val_loss: 0.4088\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.0251 - val_loss: 0.4075\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.0249 - val_loss: 0.4060\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.0248 - val_loss: 0.4043\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.0246 - val_loss: 0.4026\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.0244 - val_loss: 0.4009\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.0243 - val_loss: 0.3992\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.0241 - val_loss: 0.3975\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.0239 - val_loss: 0.3958\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.0238 - val_loss: 0.3942\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.0236 - val_loss: 0.3927\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.0235 - val_loss: 0.3914\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.0233 - val_loss: 0.3901\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.0232 - val_loss: 0.3889\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.0230 - val_loss: 0.3877\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.0229 - val_loss: 0.3864\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.0228 - val_loss: 0.3850\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.0227 - val_loss: 0.3835\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.0226 - val_loss: 0.3818\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.0225 - val_loss: 0.3801\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.0224 - val_loss: 0.3784\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.0223 - val_loss: 0.3765\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.0222 - val_loss: 0.3747\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.0221 - val_loss: 0.3731\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.0221 - val_loss: 0.3717\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.0220 - val_loss: 0.3705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.0219 - val_loss: 0.3694\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.0218 - val_loss: 0.3684\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.0218 - val_loss: 0.3675\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.0217 - val_loss: 0.3665\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.0216 - val_loss: 0.3656\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.0216 - val_loss: 0.3647\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.0215 - val_loss: 0.3638\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.0214 - val_loss: 0.3628\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.0214 - val_loss: 0.3619\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.0213 - val_loss: 0.3609\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.0213 - val_loss: 0.3598\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.0212 - val_loss: 0.3586\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.0212 - val_loss: 0.3573\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.0211 - val_loss: 0.3559\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.0211 - val_loss: 0.3544\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.0210 - val_loss: 0.3529\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.0209 - val_loss: 0.3514\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.0209 - val_loss: 0.3499\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.0208 - val_loss: 0.3484\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.0208 - val_loss: 0.3470\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.0207 - val_loss: 0.3457\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.0207 - val_loss: 0.3445\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.0206 - val_loss: 0.3435\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.0206 - val_loss: 0.3426\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.0205 - val_loss: 0.3417\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.0205 - val_loss: 0.3408\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.0204 - val_loss: 0.3396\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.0204 - val_loss: 0.3385\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.0204 - val_loss: 0.3373\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.0203 - val_loss: 0.3361\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.0203 - val_loss: 0.3350\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.0203 - val_loss: 0.3344\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.0202 - val_loss: 0.3339\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.0202 - val_loss: 0.3336\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.0202 - val_loss: 0.3333\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.0201 - val_loss: 0.3332\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.0201 - val_loss: 0.3328\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.0201 - val_loss: 0.3321\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.0200 - val_loss: 0.3313\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.0200 - val_loss: 0.3305\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.0200 - val_loss: 0.3300\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.0200 - val_loss: 0.3298\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.0199 - val_loss: 0.3296\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.0199 - val_loss: 0.3295\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.0199 - val_loss: 0.3294\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.0199 - val_loss: 0.3292\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.0198 - val_loss: 0.3289\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.0198 - val_loss: 0.3286\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.0198 - val_loss: 0.3284\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.0198 - val_loss: 0.3283\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.0197 - val_loss: 0.3282\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.0197 - val_loss: 0.3279\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.0197 - val_loss: 0.3276\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.0197 - val_loss: 0.3274\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=200, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "802831f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e8bd9a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024FCB5C9160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test RMSE: 1976.606\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
